{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7105f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568d6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205774da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a101c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers\\computers\\papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1310.7911v2',\n",
       " 'math/9711204v1',\n",
       " '2208.00733v1',\n",
       " '2504.07020v1',\n",
       " '2403.03925v1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"computers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "084ef30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad3c3033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('1310.7911v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a17f22",
   "metadata": {},
   "source": [
    "###Tool Schema\n",
    "\n",
    "Here are the schema of each tool which you will provide to the LLM. \n",
    "We are going to pass these tools to LLM (Claude/gemini).\n",
    "Then we will build a chatbot that will take in these tools and knows when to call them to return the data.\n",
    "Each tool we define will have a \"name\", \"description\" and then some schema that it needs to follow\n",
    "LLM will not call the functions, we are goign to write the code to call those functions and pass the data back to the model.\n",
    "But these tools are going to allow the model to extend it's functionality so instead of saying 'I don't know' or hallucinate we'll get the answer that we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a9c0d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This works with anthropic library for claude model\n",
    "tools_anthropic = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7873ab5",
   "metadata": {},
   "source": [
    "Tools for Google genai library with Gemini model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d02704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "tools_google = [\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            {\n",
    "                \"name\": tool.get(\"name\"),\n",
    "                \"description\": tool.get(\"description\"),\n",
    "                \"parameters\": {\n",
    "                    k: v\n",
    "                    for k, v in tool.get(\"input_schema\").items()\n",
    "                    if k not in [\"additionalProperties\", \"$schema\"]\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    for tool in tools_anthropic\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb877a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "    print(f\"execute_tools result:{result}\")\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24dcc2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77c950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eced1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.5-flash-preview-04-17',\n",
    "        contents=json.dumps(messages),\n",
    "        config={'tools':tools_google})\n",
    "    \n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "\n",
    "        if response.text :\n",
    "            assistant_content.append(response.text)\n",
    "            print(response.text)\n",
    "            #if len(response.text) == 1:\n",
    "            process_query = False\n",
    "        \n",
    "        elif response.function_calls:\n",
    "            for content in response.function_calls:\n",
    "                \n",
    "                assistant_content.append(json.dumps(content.to_json_dict()))\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.args\n",
    "                tool_name = content.name\n",
    "                \n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\"role\": \"user\", \n",
    "                                    \"content\": [\n",
    "                                        {\n",
    "                                            \"type\": \"tool_result\",\n",
    "                                            \"tool_name\": tool_name,\n",
    "                                            \"content\": json.dumps(result)\n",
    "                                        }\n",
    "                                    ]\n",
    "                                })\n",
    "                response = client.models.generate_content(\n",
    "                            model='gemini-2.5-flash-preview-04-17',\n",
    "                            contents= json.dumps(messages),\n",
    "                            config={'tools':tools_google})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a10da95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a864f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Hello! How can I help you today?\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool search_papers with args {'topic': 'trigonometry'}\n",
      "Results are saved in: papers\\trigonometry\\papers_info.json\n",
      "execute_tools result:['1206.1761v1', '2503.11678v1', 'math-ph/9910041v1', 'math-ph/0112030v1', '0911.1025v1']\n",
      "\n",
      "Error: 500 INTERNAL. {'error': {'code': 500, 'message': 'An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting', 'status': 'INTERNAL'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool extract_info with args {'paper_id': '1206.1761v1'}\n",
      "execute_tools result:{\n",
      "  \"title\": \"Trigonometry of The Gold-Bug\",\n",
      "  \"authors\": [\n",
      "    \"Erik Talvila\"\n",
      "  ],\n",
      "  \"summary\": \"The classic Edgar Allan Poe story The Gold-Bug involves digging for pirate\\ntreasure. Locating the digging sites requires some simple trigonometry.\",\n",
      "  \"pdf_url\": \"http://arxiv.org/pdf/1206.1761v1\",\n",
      "  \"published\": \"2012-05-31\"\n",
      "}\n",
      "Calling tool extract_info with args {'paper_id': '2503.11678v1'}\n",
      "execute_tools result:{\n",
      "  \"title\": \"A New Approach to Learn Trigonometry\",\n",
      "  \"authors\": [\n",
      "    \"Marcia Ann Surya\",\n",
      "    \"Yohanes Surya\"\n",
      "  ],\n",
      "  \"summary\": \"We introduce the Primary Gasing Triangle, a right triangle with a hypotenuse\\nof 1 unit, to define the primary trigonometric functions: sine and cosine. This\\ntriangle serves as the foundational element in a new approach to learning\\ntrigonometry, enabling us to derive the Derived Gasing Triangle, where the\\nother four trigonometric functions (tangent, secant, cotangent, and cosecant)\\nare defined. Using the Primary Gasing Triangle, we derive key trigonometric\\nformulas, provide several proofs of the Pythagorean theorem using trigonometry,\\nand solve various trigonometry problems. This approach makes learning\\ntrigonometry simpler, easier, and more intuitive.\",\n",
      "  \"pdf_url\": \"http://arxiv.org/pdf/2503.11678v1\",\n",
      "  \"published\": \"2025-03-03\"\n",
      "}\n",
      "Here are the summaries for the papers you requested:\n",
      "\n",
      "**Paper: '1206.1761v1'**\n",
      "*   **Title:** Trigonometry of The Gold-Bug\n",
      "*   **Authors:** Erik Talvila\n",
      "*   **Summary:** The classic Edgar Allan Poe story The Gold-Bug involves digging for pirate treasure. Locating the digging sites requires some simple trigonometry.\n",
      "\n",
      "**Paper: '2503.11678v1'**\n",
      "*   **Title:** A New Approach to Learn Trigonometry\n",
      "*   **Authors:** Marcia Ann Surya, Yohanes Surya\n",
      "*   **Summary:** This paper introduces the Primary Gasing Triangle, a right triangle with a hypotenuse of 1, to define sine and cosine as the primary trigonometric functions. This concept is used to derive other trigonometric functions and formulas, provide proofs for the Pythagorean theorem, and solve trigonometry problems, aiming to make learning trigonometry simpler and more intuitive.\n",
      "\n",
      "\n",
      "That's great to hear! How can I help you today?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
